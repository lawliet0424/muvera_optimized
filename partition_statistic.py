#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Partition Masking and Utilization Statistics Calculator
1) doc_idxë³„ë¡œ ìœ íš¨ partition ë§ˆìŠ¤í‚¹ ìƒì„± (count > 0ì¸ partition)
2) ë§ˆìŠ¤í‚¹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ partitionë³„ í™œìš©ë„ í†µê³„ ê³„ì‚°

Usage:
  python3 partition_statistic.py --dataset scidocs --filename main_weight_kmeans_gpu --method kmeans --csv_file partition_count.csv --rep 1 --partition_idx 4 --rerank 0 --output partition_statistic_result.csv --output_mask partition_masking.csv --output_rep_stats partition_utilization.csv
  python3 partition_statistic.py -d scidocs -f main_weight_kmeans_gpu -m kmeans -c partition_count.csv -p 1 -pi 4 -rk 0 -out partition_statistic_result.csv -outm partition_masking.csv -outr partition_utilization.csv
"""

import sys
import os
import argparse
import pandas as pd
import numpy as np


def parse_arguments():
    parser = argparse.ArgumentParser(
        description='Partition ë§ˆìŠ¤í‚¹ ë° í™œìš©ë„ í†µê³„ ê³„ì‚°',
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument('--dataset', '-d', help='ë°ì´í„°ì…‹ ì´ë¦„')
    parser.add_argument('--filename', '-f', type=str, required=True,
                        help='íŒŒì¼ ì´ë¦„')
    parser.add_argument('--method', '-m', help='ë©”ì„œë“œ ì´ë¦„')
    parser.add_argument('--rep', '-p', type=int, required=True,
                        help='ë¶„ì„í•  repetition ë²ˆí˜¸')
    parser.add_argument('--partition_idx', '-pi', type=int, required=True,
                        help='ë¶„ì„í•  partition ì¸ë±ìŠ¤ ê°œìˆ˜')
    parser.add_argument('--rerank', '-rk', type=int, required=True,
                        help='ë¶„ì„í•  rerank ê°œìˆ˜')
    parser.add_argument('--csv_file', '-c', help='ë¶„ì„í•  CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--rep_num', '-rn', type=int, 
                        help='ë¶„ì„í•  repetition ë²ˆí˜¸ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ repetition ë¶„ì„)')
    parser.add_argument('--output', '-out', help='ê²°ê³¼ë¥¼ ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ (ì„ íƒ)')
    parser.add_argument('--output_mask', '-outm', help='ë§ˆìŠ¤í‚¹ ê²°ê³¼ë¥¼ ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ (ì„ íƒ)')
    parser.add_argument('--output_rep_stats', '-outr', help='Repetitionë³„ í†µê³„ë¥¼ ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ (ì„ íƒ)')
    parser.add_argument('--projection', '-pr', type=int, default=128,
                        help='í”„ë¡œì ì…˜ ì°¨ì› ìˆ˜ (ê¸°ë³¸ê°’: 128)')
    
    return parser.parse_args()


def load_csv(file_path):
    """CSV íŒŒì¼ ë¡œë“œ"""
    try:
        df = pd.read_csv(file_path)
        print(f"âœ… CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {file_path}")
        print(f"   - ì „ì²´ í–‰ ìˆ˜: {len(df)}")
        print(f"   - ì „ì²´ ì¹¼ëŸ¼: {list(df.columns)}")
        return df
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)


def validate_dataframe(df):
    """ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° ê²€ì¦"""
    required_cols = ['doc_idx', 'rep_num', 'partition_idx', 'count']
    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        print(f"âŒ ë‹¤ìŒ ì¹¼ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {missing}")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì¹¼ëŸ¼: {list(df.columns)}")
        sys.exit(1)
    print(f"âœ… ë°ì´í„° êµ¬ì¡° í™•ì¸ ì™„ë£Œ")


def create_partition_masking(df, rep_num):
    """
    Step 1: doc_idxë³„ë¡œ partition ë§ˆìŠ¤í‚¹ ìƒì„±
    count > 0ì¸ partitionì€ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0
    
    Returns:
        masking_df: DataFrame with columns [doc_idx, rep_num, partition_masking, active_partition_count]
    """
    print(f"\nğŸ“Š Step 1: doc_idxë³„ Partition ë§ˆìŠ¤í‚¹ ìƒì„± ì¤‘ (rep_num={rep_num})...")
    
    # í•´ë‹¹ repetitionë§Œ í•„í„°ë§
    df_filtered = df[df['rep_num'] == rep_num].copy()
    
    if len(df_filtered) == 0:
        print(f"âŒ rep_num={rep_num}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
    
    # partition ê°œìˆ˜ í™•ì¸
    num_partitions = df_filtered['partition_idx'].nunique()
    partition_indices = sorted(df_filtered['partition_idx'].unique())
    print(f"   - Partition ê°œìˆ˜: {num_partitions}")
    print(f"   - Partition ì¸ë±ìŠ¤: {partition_indices}")
    
    # doc_idx ëª©ë¡
    doc_indices = sorted(df_filtered['doc_idx'].unique())
    print(f"   - Document ê°œìˆ˜: {len(doc_indices)}")
    
    masking_results = []
    
    for doc_idx in doc_indices:
        # í•´ë‹¹ doc_idxì˜ ë°ì´í„°
        doc_data = df_filtered[df_filtered['doc_idx'] == doc_idx].sort_values('partition_idx')
        
        # ë§ˆìŠ¤í‚¹ ìƒì„±: count > 0ì´ë©´ 1, ì•„ë‹ˆë©´ 0
        mask = (doc_data['count'] > 0).astype(int).tolist()
        mask_str = ''.join(map(str, mask))
        
        # í™œì„± partition ê°œìˆ˜
        active_count = sum(mask)
        
        masking_results.append({
            'doc_idx': doc_idx,
            'rep_num': rep_num,
            'partition_masking': mask_str,
            'active_partition_count': active_count
        })
        
        if doc_idx < 5:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"   - doc_idx {doc_idx}: {mask_str} (í™œì„± íŒŒí‹°ì…˜: {active_count}ê°œ)")
    
    masking_df = pd.DataFrame(masking_results)
    print(f"âœ… ë§ˆìŠ¤í‚¹ ìƒì„± ì™„ë£Œ: {len(masking_df)}ê°œ ë¬¸ì„œ")
    
    return masking_df, df_filtered, partition_indices


def calculate_partition_utilization(df_filtered, masking_df, partition_indices, rep_num):
    """
    Step 2: ë§ˆìŠ¤í‚¹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ partitionë³„ í™œìš©ë„ í†µê³„ ê³„ì‚°
    
    Returns:
        utilization_df: DataFrame with partition utilization statistics
    """
    print(f"\nğŸ“Š Step 2: Partitionë³„ í™œìš©ë„ í†µê³„ ê³„ì‚° ì¤‘...")
    
    utilization_results = []
    
    for partition_idx in partition_indices:
        # í•´ë‹¹ partitionì˜ ëª¨ë“  ë°ì´í„°
        partition_data = df_filtered[df_filtered['partition_idx'] == partition_idx].copy()
        
        # ë§ˆìŠ¤í‚¹ì—ì„œ í•´ë‹¹ partition ìœ„ì¹˜ì˜ ê°’ ì¶”ì¶œ
        mask_values = []
        for _, row in masking_df.iterrows():
            mask_str = row['partition_masking']
            if partition_idx < len(mask_str):
                mask_values.append(int(mask_str[partition_idx]))
            else:
                mask_values.append(0)
        
        # í™œìš©ëœ ë¬¸ì„œ ê°œìˆ˜ (mask=1ì¸ ê°œìˆ˜)
        utilized_count = sum(mask_values)
        total_docs = len(masking_df)
        utilization_rate = (utilized_count / total_docs * 100) if total_docs > 0 else 0
        
        # count ê°’ í†µê³„ (ë§ˆìŠ¤í‚¹ëœ ë¬¸ì„œë§Œ ëŒ€ìƒ)
        masked_counts = []
        for idx, (_, row) in enumerate(masking_df.iterrows()):
            doc_idx = row['doc_idx']
            mask_str = row['partition_masking']
            
            if partition_idx < len(mask_str) and mask_str[partition_idx] == '1':
                # ë§ˆìŠ¤í‚¹ì´ 1ì¸ ê²½ìš°ë§Œ count ê°’ ìˆ˜ì§‘
                count_value = partition_data[partition_data['doc_idx'] == doc_idx]['count'].values
                if len(count_value) > 0:
                    masked_counts.append(count_value[0])
        
        # í†µê³„ ê³„ì‚°
        if len(masked_counts) > 0:
            count_sum = sum(masked_counts)
            count_mean = np.mean(masked_counts)
            count_median = np.median(masked_counts)
            count_std = np.std(masked_counts)
            count_min = min(masked_counts)
            count_max = max(masked_counts)
        else:
            count_sum = count_mean = count_median = count_std = count_min = count_max = 0
        
        utilization_results.append({
            'rep_num': rep_num,
            'partition_idx': partition_idx,
            'utilized_docs': utilized_count,
            'total_docs': total_docs,
            'utilization_rate(%)': utilization_rate,
            'count_sum': count_sum,
            'count_mean': count_mean,
            'count_median': count_median,
            'count_std': count_std,
            'count_min': count_min,
            'count_max': count_max
        })
    
    utilization_df = pd.DataFrame(utilization_results)
    print(f"âœ… í™œìš©ë„ í†µê³„ ê³„ì‚° ì™„ë£Œ: {len(utilization_df)}ê°œ íŒŒí‹°ì…˜")
    
    return utilization_df


def print_masking_summary(masking_df, output_file=None):
    """ë§ˆìŠ¤í‚¹ ìš”ì•½ ì •ë³´ ì¶œë ¥"""
    output_lines = []
    output_lines.append("\n" + "="*80)
    output_lines.append("ğŸ“‹ ë§ˆìŠ¤í‚¹ ìš”ì•½")
    output_lines.append("="*80)
    output_lines.append(f"ì´ ë¬¸ì„œ ìˆ˜: {len(masking_df)}")
    output_lines.append(f"í™œì„± íŒŒí‹°ì…˜ ê°œìˆ˜ í†µê³„:")
    output_lines.append(f"  - í‰ê· : {masking_df['active_partition_count'].mean():.2f}")
    output_lines.append(f"  - ì¤‘ê°„ê°’: {masking_df['active_partition_count'].median():.2f}")
    output_lines.append(f"  - ìµœì†Œ: {masking_df['active_partition_count'].min()}")
    output_lines.append(f"  - ìµœëŒ€: {masking_df['active_partition_count'].max()}")
    output_lines.append(f"  - í‘œì¤€í¸ì°¨: {masking_df['active_partition_count'].std():.2f}")
    output_lines.append("="*80)
    
    output_text = "\n".join(output_lines)
    print(output_text)
    
    if output_file:
        output_file.write(output_text + "\n")
        output_file.flush()


def print_utilization_table(utilization_df, output_file=None):
    """í™œìš©ë„ ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“ˆ Partitionë³„ í™œìš©ë„ í†µê³„")
    print("="*80)
    
    # í¬ë§·íŒ…ëœ ì¶œë ¥
    pd.options.display.float_format = '{:.2f}'.format
    print(utilization_df.to_string(index=False))
    
    # ì „ì²´ ìš”ì•½ ë¶€ë¶„ (íŒŒì¼ ì €ì¥ìš©)
    summary_lines = []
    summary_lines.append("\n" + "-"*80)
    summary_lines.append("ğŸ“Š ì „ì²´ ìš”ì•½:")
    summary_lines.append(f"  - í‰ê·  í™œìš©ë¥ : {utilization_df['utilization_rate(%)'].mean():.2f}%")
    summary_lines.append(f"  - ê°€ì¥ ë§ì´ í™œìš©ëœ íŒŒí‹°ì…˜: {utilization_df.loc[utilization_df['utilization_rate(%)'].idxmax(), 'partition_idx']} "
          f"({utilization_df['utilization_rate(%)'].max():.2f}%)")
    summary_lines.append(f"  - ê°€ì¥ ì ê²Œ í™œìš©ëœ íŒŒí‹°ì…˜: {utilization_df.loc[utilization_df['utilization_rate(%)'].idxmin(), 'partition_idx']} "
          f"({utilization_df['utilization_rate(%)'].min():.2f}%)")
    summary_lines.append(f"  - ì „ì²´ count í•©ê³„: {utilization_df['count_sum'].sum():.0f}")
    summary_lines.append("="*80)
    
    summary_text = "\n".join(summary_lines)
    print(summary_text)
    
    if output_file:
        output_file.write(summary_text + "\n")
        output_file.flush()


def calculate_repetition_statistics(all_utilization_df):
    """
    Repetitionë³„ í†µê³„ ê³„ì‚°
    ê° repetitionì˜ partition í™œìš©ë„ë¥¼ ì§‘ê³„
    """
    print(f"\nğŸ“Š Repetitionë³„ í†µê³„ ê³„ì‚° ì¤‘...")
    
    rep_stats = []
    
    for rep_num in sorted(all_utilization_df['rep_num'].unique()):
        rep_data = all_utilization_df[all_utilization_df['rep_num'] == rep_num]
        
        rep_stats.append({
            'rep_num': rep_num,
            'avg_utilization_rate(%)': rep_data['utilization_rate(%)'].mean(),
            'std_utilization_rate(%)': rep_data['utilization_rate(%)'].std(),
            'min_utilization_rate(%)': rep_data['utilization_rate(%)'].min(),
            'max_utilization_rate(%)': rep_data['utilization_rate(%)'].max(),
            'total_count_sum': rep_data['count_sum'].sum(),
            'avg_count_mean': rep_data['count_mean'].mean(),
            'avg_utilized_docs': rep_data['utilized_docs'].mean(),
            'partitions': len(rep_data)
        })
    
    rep_stats_df = pd.DataFrame(rep_stats)
    print(f"âœ… Repetitionë³„ í†µê³„ ê³„ì‚° ì™„ë£Œ: {len(rep_stats_df)}ê°œ repetition")
    
    return rep_stats_df


def print_repetition_statistics(rep_stats_df):
    """Repetitionë³„ í†µê³„ í…Œì´ë¸” ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“ˆ Repetitionë³„ í†µê³„")
    print("="*80)
    
    pd.options.display.float_format = '{:.2f}'.format
    print(rep_stats_df.to_string(index=False))
    
    print("\n" + "-"*80)
    print("ğŸ“Š Repetition ê°„ ë¹„êµ:")
    print(f"  - í‰ê·  í™œìš©ë¥ ì´ ê°€ì¥ ë†’ì€ repetition: {rep_stats_df.loc[rep_stats_df['avg_utilization_rate(%)'].idxmax(), 'rep_num']} "
          f"({rep_stats_df['avg_utilization_rate(%)'].max():.2f}%)")
    print(f"  - í‰ê·  í™œìš©ë¥ ì´ ê°€ì¥ ë‚®ì€ repetition: {rep_stats_df.loc[rep_stats_df['avg_utilization_rate(%)'].idxmin(), 'rep_num']} "
          f"({rep_stats_df['avg_utilization_rate(%)'].min():.2f}%)")
    print(f"  - ì „ì²´ count í•©ê³„ê°€ ê°€ì¥ ë†’ì€ repetition: {rep_stats_df.loc[rep_stats_df['total_count_sum'].idxmax(), 'rep_num']} "
          f"({rep_stats_df['total_count_sum'].max():.0f})")
    print("="*80)


def save_results(df, output_path, description):
    """ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        df.to_csv(output_path, index=False)
        print(f"\nâœ… {description} ì €ì¥ ì™„ë£Œ: {output_path}")
    except Exception as e:
        print(f"\nâŒ {description} ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    args = parse_arguments()

    if args.projection == 128:
        common_file_path = os.path.join("/media/dcceris/muvera_optimized", "cache_muvera", args.dataset, args.filename, "query_search", f"rep{args.rep}_{args.method}{args.partition_idx}_rerank{args.rerank}")
    else:
        common_file_path = os.path.join("/media/dcceris/muvera_optimized", "cache_muvera", args.dataset, args.filename, "query_search", f"rep{args.rep}_{args.method}{args.partition_idx}_rerank{args.rerank}_proj{args.projection}")
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì • (partition_count_result.txt í˜•íƒœ)
    output_txt_path = os.path.join(common_file_path, f"partition_count_result.txt")
    
    # 1. CSV ë¡œë“œ
    df = load_csv(os.path.join(common_file_path, args.csv_file))
    
    # 2. ë°ì´í„° ê²€ì¦
    validate_dataframe(df)
    
    # 3. Repetition ëª©ë¡ í™•ì¸
    all_rep_nums = sorted(df['rep_num'].unique())
    print(f"\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ Repetition: {all_rep_nums}")
    
    # 4. ë¶„ì„í•  repetition ê²°ì •
    if args.rep_num is not None:
        # íŠ¹ì • repetitionë§Œ ë¶„ì„
        rep_nums_to_analyze = [args.rep_num]
        print(f"âœ… ë‹¨ì¼ Repetition ë¶„ì„ ëª¨ë“œ: rep_num={args.rep_num}")
    else:
        # ì „ì²´ repetition ë¶„ì„
        rep_nums_to_analyze = all_rep_nums
        print(f"âœ… ì „ì²´ Repetition ë¶„ì„ ëª¨ë“œ: {len(rep_nums_to_analyze)}ê°œ repetition")
    
    # 5. ê° repetitionì— ëŒ€í•´ ë¶„ì„ ìˆ˜í–‰
    all_masking_dfs = []
    all_utilization_dfs = []
    
    # result.txt íŒŒì¼ ì—´ê¸° (ë§ˆìŠ¤í‚¹ ìš”ì•½ê³¼ ì „ì²´ ìš”ì•½ë§Œ ì €ì¥)
    with open(output_txt_path, 'w', encoding='utf-8') as result_file:
        for rep_num in rep_nums_to_analyze:
            print(f"\n{'='*80}")
            print(f"ğŸ” Repetition {rep_num} ë¶„ì„ ì‹œì‘")
            print(f"{'='*80}")
            
            # Step 1: Partition ë§ˆìŠ¤í‚¹ ìƒì„±
            masking_df, df_filtered, partition_indices = create_partition_masking(df, rep_num)
            
            if masking_df is None:
                print(f"âš ï¸  rep_num={rep_num} ê±´ë„ˆëœ€")
                continue
            
            # ë§ˆìŠ¤í‚¹ ìš”ì•½ ì¶œë ¥ ë° íŒŒì¼ ì €ì¥
            print_masking_summary(masking_df, result_file)
            
            # Step 2: Partition í™œìš©ë„ í†µê³„ ê³„ì‚°
            utilization_df = calculate_partition_utilization(df_filtered, masking_df, partition_indices, rep_num)
            
            # ê²°ê³¼ ì¶œë ¥ ë° ì „ì²´ ìš”ì•½ íŒŒì¼ ì €ì¥
            print_utilization_table(utilization_df, result_file)
            
            # ê²°ê³¼ ì €ì¥
            all_masking_dfs.append(masking_df)
            all_utilization_dfs.append(utilization_df)
    
    # 6. ì „ì²´ ê²°ê³¼ í†µí•©
    combined_masking_df = pd.concat(all_masking_dfs, ignore_index=True)
    combined_utilization_df = pd.concat(all_utilization_dfs, ignore_index=True)
    
    # 7. Repetitionë³„ í†µê³„ ê³„ì‚° (ì—¬ëŸ¬ repetitionì„ ë¶„ì„í•œ ê²½ìš°)
    if len(rep_nums_to_analyze) > 1:
        rep_stats_df = calculate_repetition_statistics(combined_utilization_df)
        print_repetition_statistics(rep_stats_df)
        
        # Repetitionë³„ í†µê³„ ì €ì¥
        if args.output_rep_stats:
            save_results(rep_stats_df, os.path.join(common_file_path, args.output), "Repetitionë³„ í†µê³„")
        else:
            # base_nameì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ê²½ë¡œ ì œê±°)
            default_rep_stats_output = os.path.join(common_file_path, args.output)
            save_results(rep_stats_df, default_rep_stats_output, "Repetitionë³„ í†µê³„")
    
    # 8. ê²°ê³¼ íŒŒì¼ ì €ì¥
    if args.output_mask:
        save_results(combined_masking_df, os.path.join(common_file_path, args.output_mask), "ë§ˆìŠ¤í‚¹ ê²°ê³¼")
    else:
        # base_nameì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ê²½ë¡œ ì œê±°)
        if len(rep_nums_to_analyze) == 1:
            default_mask_output = os.path.join(common_file_path, args.output_mask)
        else:
            default_mask_output = os.path.join(common_file_path, args.output_mask)
        save_results(combined_masking_df, default_mask_output, "ë§ˆìŠ¤í‚¹ ê²°ê³¼")
    
    # 9. í™œìš©ë„ í†µê³„ ì €ì¥ (utilization íŒŒì¼ - result.txtì™€ ë…ë¦½ì )
    if args.output:
        utilization_output_path = os.path.join(common_file_path, args.output_rep_stats)
        save_results(combined_utilization_df, utilization_output_path, "í™œìš©ë„ í†µê³„")
    else:
        # base_nameì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ê²½ë¡œ ì œê±°)
        if len(rep_nums_to_analyze) == 1:
            default_util_output = os.path.join(common_file_path, f"{args.output_rep_stats}_rep{rep_nums_to_analyze[0]}.csv")
        else:
            default_util_output = os.path.join(common_file_path, f"{args.output_rep_stats}_all.csv")
        save_results(combined_utilization_df, default_util_output, "í™œìš©ë„ í†µê³„")
    
    # 10. result.txt íŒŒì¼ ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ (utilization íŒŒì¼ê³¼ ë…ë¦½ì )
    print(f"\nâœ… ì¶œë ¥ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
    print(f"   - í…ìŠ¤íŠ¸ ìš”ì•½: {output_txt_path}")


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python3 partition_masking_stats.py <csv_file> --rep-num <rep_number>")
        print("ë„ì›€ë§: python3 partition_masking_stats.py --help")
        sys.exit(1)
    
    main()